{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f9abb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,LabelEncoder, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, log_loss\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbdabd49",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Merging\n",
    "\n",
    "We'll start by loading our two datasets:\n",
    "1. `customer_social_profiles.csv`: Contains social media engagement data\n",
    "2. `customer_transactions.csv`: Contains transaction history\n",
    "\n",
    "We'll need to:\n",
    "1. Load both datasets\n",
    "2. Clean and preprocess the data\n",
    "3. Merge the datasets based on customer ID\n",
    "4. Perform feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b523b2ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customer Social Profiles Dataset:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 155 entries, 0 to 154\n",
      "Data columns (total 5 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   customer_id_new          155 non-null    object \n",
      " 1   social_media_platform    155 non-null    object \n",
      " 2   engagement_score         155 non-null    int64  \n",
      " 3   purchase_interest_score  155 non-null    float64\n",
      " 4   review_sentiment         155 non-null    object \n",
      "dtypes: float64(1), int64(1), object(3)\n",
      "memory usage: 6.2+ KB\n",
      "None\n",
      "\n",
      "Customer Transactions Dataset:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 6 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   customer_id_legacy  150 non-null    int64  \n",
      " 1   transaction_id      150 non-null    int64  \n",
      " 2   purchase_amount     150 non-null    int64  \n",
      " 3   purchase_date       150 non-null    object \n",
      " 4   product_category    150 non-null    object \n",
      " 5   customer_rating     140 non-null    float64\n",
      "dtypes: float64(1), int64(3), object(2)\n",
      "memory usage: 7.2+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Load the datasets\n",
    "social_profiles = pd.read_csv('../data/tables/customer_social_profiles.csv')\n",
    "transactions = pd.read_csv('../data/tables/customer_transactions.csv')\n",
    "\n",
    "# Display basic information about the datasets\n",
    "print(\"Customer Social Profiles Dataset:\")\n",
    "print(social_profiles.info())\n",
    "print(\"\\nCustomer Transactions Dataset:\")\n",
    "print(transactions.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d566b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean and preprocess data\n",
    "# Convert customer IDs to a common format (removing 'A' prefix from social profiles)\n",
    "social_profiles['customer_id'] = social_profiles['customer_id_new'].str[1:].astype(int)\n",
    "transactions['customer_id'] = transactions['customer_id_legacy'].astype(int)\n",
    "\n",
    "# Merge datasets\n",
    "merged_data = pd.merge(\n",
    "    social_profiles,\n",
    "    transactions,\n",
    "    on='customer_id',\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "# Feature engineering\n",
    "# Convert date to datetime\n",
    "merged_data['purchase_date'] = pd.to_datetime(merged_data['purchase_date'])\n",
    "\n",
    "# Create additional features\n",
    "merged_data['engagement_purchase_ratio'] = merged_data['engagement_score'] / merged_data['purchase_amount']\n",
    "merged_data['sentiment_numeric'] = merged_data['review_sentiment'].map({'Positive': 1, 'Neutral': 0, 'Negative': -1})\n",
    "\n",
    "# Display merged dataset info\n",
    "print(\"Merged Dataset Information:\")\n",
    "print(merged_data.info())\n",
    "\n",
    "# Fill missing values \n",
    "for col in merged_data.columns:\n",
    "    if merged_data[col].dtype in ['int64', 'float64']:\n",
    "        # Use median for robustness (handles skewed distributions better)\n",
    "        merged_data[col].fillna(merged_data[col].median(), inplace=True)\n",
    "    else:\n",
    "        # For categorical columns, fill with mode (most common value)\n",
    "        merged_data[col].fillna(merged_data[col].mode()[0], inplace=True)\n",
    "\n",
    "# Save merged dataset\n",
    "merged_data.to_csv('../data/tables/merged_customer_data.csv', index=False)\n",
    "print(\"\\nMerged dataset saved to tables folder\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4def7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the merged dataset\n",
    "data = pd.read_csv('../data/tables/merged_customer_data.csv')\n",
    "\n",
    "# Prepare features and target\n",
    "features = ['engagement_score', 'purchase_interest_score', 'sentiment_numeric', \n",
    "            'purchase_amount', 'customer_rating', 'engagement_purchase_ratio', \n",
    "            'social_media_platform']\n",
    "X = data[features]\n",
    "\n",
    "# One-hot encode categorical variables\n",
    "X = pd.get_dummies(X, columns=['social_media_platform'])\n",
    "\n",
    "# Encode the target variable\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(data['product_category'])\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the Random Forest model\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "y_pred_proba = model.predict_proba(X_test)\n",
    "loss = log_loss(y_test, y_pred_proba)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"F1-Score: {f1:.2f}\")\n",
    "print(f\"Log Loss: {loss:.2f}\")\n",
    "\n",
    "# Function to predict product for a new customer\n",
    "def predict_product(customer_data):\n",
    "    customer_df = pd.DataFrame([customer_data])\n",
    "    customer_df = pd.get_dummies(customer_df, columns=['social_media_platform'])\n",
    "    # Align columns with training data\n",
    "    customer_df = customer_df.reindex(columns=X.columns, fill_value=0)\n",
    "    prediction = model.predict(customer_df)\n",
    "    return le.inverse_transform(prediction)[0]\n",
    "\n",
    "# Function to get aggregated customer data based on identified ID\n",
    "def get_customer_data(customer_id, current_platform=None):\n",
    "    # Filter data for the identified customer\n",
    "    customer_data = data[data['customer_id'] == customer_id]\n",
    "    \n",
    "    if current_platform and current_platform in customer_data['social_media_platform'].values:\n",
    "        # Filter by current platform if provided and available\n",
    "        customer_data = customer_data[customer_data['social_media_platform'] == current_platform]\n",
    "    \n",
    "    # Aggregate numerical features (mean values)\n",
    "    aggregated_data = {\n",
    "        'engagement_score': customer_data['engagement_score'].mean(),\n",
    "        'purchase_interest_score': customer_data['purchase_interest_score'].mean(),\n",
    "        'sentiment_numeric': customer_data['sentiment_numeric'].mean(),\n",
    "        'purchase_amount': customer_data['purchase_amount'].mean(),\n",
    "        'customer_rating': customer_data['customer_rating'].mean(),\n",
    "        'engagement_purchase_ratio': customer_data['engagement_purchase_ratio'].mean(),\n",
    "        'social_media_platform': customer_data['social_media_platform'].mode()[0] if not current_platform else current_platform\n",
    "    }\n",
    "    return aggregated_data\n",
    "\n",
    "# Simulate facial recognition and run recommendation\n",
    "if __name__ == \"__main__\":\n",
    "    # Simulate facial recognition (replace with actual model output)\n",
    "    identified_customer_id = 190  # Example: User identified as customer_id 190 (A190)\n",
    "\n",
    "    customer_data = get_customer_data(identified_customer_id)\n",
    "    print(f\"Customer Data: {customer_data}\")\n",
    "    \n",
    "    # Predict product\n",
    "    recommended_product = predict_product(customer_data)\n",
    "    print(f\"Recommended Product: {recommended_product}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virtual_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
